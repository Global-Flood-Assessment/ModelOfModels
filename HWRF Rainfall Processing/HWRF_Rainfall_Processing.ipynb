{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import csv\n",
    "import json\n",
    "from rasterio.mask import mask\n",
    "import os\n",
    "import numpy as np\n",
    "from rasterio import Affine\n",
    "import math\n",
    "from datetime import date,timedelta,datetime\n",
    "import requests, wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "watersheds=gpd.read_file(\"Watershed_pfaf_id.shp\")\n",
    "watersheds.set_index(\"pfaf_id\",inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HWRF_extract_by_mask(mask_json,tiff):\n",
    "    with rasterio.open(tiff) as src:\n",
    "        try:\n",
    "            out_image, out_transform = mask(src, [mask_json['features'][0]['geometry']], crop=True)\n",
    "        except ValueError as e:\n",
    "            #'Input shapes do not overlap raster.'\n",
    "            #print(e)\n",
    "            src = None\n",
    "            # return empty dataframe\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    # extract data\n",
    "    no_data = src.nodata\n",
    "    # extract the values of the masked array\n",
    "    #print(out_image)\n",
    "    data = out_image[0]\n",
    "    # extract the row, columns of the valid values\n",
    "    row, col = np.where(data != no_data) \n",
    "    point_value = np.extract(data != no_data, data)\n",
    "    if (len(point_value)== 0):\n",
    "        src = None\n",
    "        # return empty dataframe\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    T1 = out_transform * Affine.translation(0.5, 0.5) # reference the pixel centre\n",
    "    rc2xy = lambda r, c: (c, r) * T1  \n",
    "    px,py=src.res\n",
    "    #print (px,py)\n",
    "    pixel_area_km2 = lambda lon, lat: 111.111*111.111*math.cos(lat*0.01745)*px*py \n",
    "    d = gpd.GeoDataFrame({'col':col,'row':row,'intensity':point_value})\n",
    "    # coordinate transformation\n",
    "    d['lon'] = d.apply(lambda row: rc2xy(row.row,row.col)[0], axis=1)\n",
    "    d['lat'] = d.apply(lambda row: rc2xy(row.row,row.col)[1], axis=1)\n",
    "    d['area'] = d.apply(lambda row: pixel_area_km2(row.lon,row.lat), axis=1)\n",
    "    \n",
    "    # geometry \n",
    "    d['geometry'] =d.apply(lambda row: Point(row['lon'], row['lat']), axis=1)\n",
    "    # first 2 points\n",
    "    src = None\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "##download the TC Rainfall and save as the txt file for each cyclones \n",
    "baseurl=\"https://ftpprd.ncep.noaa.gov/data/nccf/com/hur/prod/\"\n",
    "forcast_date = date.today()\n",
    "cur_year, cur_month,cur_day = map(str,[forcast_date.today().year,forcast_date.today().month,forcast_date.today().day])\n",
    "cur_month = cur_month.zfill(2)\n",
    "cur_day=cur_day.zfill(2)\n",
    "dataurl=baseurl+\"hwrf.\"+cur_year+cur_month+cur_day+\"06/\"\n",
    "response = requests.get(dataurl)\n",
    "raw_text = response.text.split()\n",
    "data_list = [x.split(\"'\")[0] for x in raw_text if \"href\" in x]\n",
    "data_list=[i for i in data_list if \"rainfall.ascii\" in i]\n",
    "TC_Rain=[]\n",
    "count=0\n",
    "for i in data_list:\n",
    "    TC_Rain.append(i.split('\"')[1])\n",
    "    if not os.path.exists(TC_Rain[count]):\n",
    "        with open(TC_Rain[count],\"w\") as f:\n",
    "            text=(requests.get(dataurl+TC_Rain[count])).text               \n",
    "            f.writelines(text)\n",
    "            count=count+1\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## VRT template to read the csv\n",
    "vrt_template=\"\"\"<OGRVRTDataSource>\n",
    "    <OGRVRTLayer name={}>\n",
    "        <SrcDataSource>{}</SrcDataSource>\n",
    "        <GeometryType>wkbPoint</GeometryType>\n",
    "        <GeometryField encoding=\"PointFromColumns\" x=\"lon\" y=\"lat\" z=\"Z\"/>\n",
    "    </OGRVRTLayer>\n",
    "</OGRVRTDataSource>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read each text file and create the separate tiff file\n",
    "for i in TC_Rain:\n",
    "    with open(i,'r') as f:\n",
    "        variable=csv.reader(f, delimiter=' ') \n",
    "        row_count=1 \n",
    "        for row in variable:\n",
    "            if row_count == 1: \n",
    "                while ('' in row):\n",
    "                    row.remove('')\n",
    "                XLC=float(row[0]) \n",
    "                XRC=float(row[1]) \n",
    "                YBC=float(row[2]) \n",
    "                YTC=float(row[3])\n",
    "                res=float(row[4])\n",
    "                nrows=float(row[5])\n",
    "                ncol=float(row[6])\n",
    "                row_count = row_count + 1\n",
    "    df = (pd.read_table(i, skiprows=1, delim_whitespace=True, names=('lat', 'lon', 'Z'))).fillna(-999)\n",
    "    df.sort_values(by=[\"lat\",\"lon\"], ascending=[False, True])\n",
    "    df=df[['lon','lat','Z']]\n",
    "    df = df[df.lon >= XLC]\n",
    "    df = df[df.lon <= XRC]\n",
    "    df = df[df.lat >= YBC]\n",
    "    df = df[df.lat <= YTC]\n",
    "    df = df[df.Z > 0]\n",
    "    df.to_csv(i.replace(\".ascii\",\".csv\"),index=False, sep=\" \")\n",
    "    with open(i.replace(\".ascii\",\".vrt\"),\"w\") as g:\n",
    "        g.write(vrt_template.format(i.replace(\".ascii\",\"\"),i.replace(\".ascii\",\".csv\")))\n",
    "    g.close()\n",
    "    r=gdal.Rasterize(i.replace(\".ascii\",\".tiff\"),i.replace(\".ascii\",\".vrt\"),outputSRS=\"EPSG:4326\",xRes=res, yRes=res,attribute=\"Z\", noData=-999)\n",
    "    r=None\n",
    "    os.remove(i.replace(\".ascii\",\".csv\"))\n",
    "    #gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.lon, df.lat)) \n",
    "    #gdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "##merge all  tiffs file and delete the individual tiff, vrt and ascii file \n",
    "TC_Rain_tiff=[]\n",
    "for i in TC_Rain:\n",
    "    TC_Rain_tiff.append(i.replace(\".ascii\",\".tiff\"))\n",
    "filename=\"hwrf.\"+cur_year+cur_month+cur_day+\"rainfall.vrt\"\n",
    "vrt = gdal.BuildVRT(filename, TC_Rain_tiff)\n",
    "gdal.Translate(filename.replace(\".vrt\",\".tiff\"), vrt)\n",
    "vrt=None\n",
    "for i in TC_Rain_tiff:\n",
    "    os.remove(i)\n",
    "    os.remove(i.replace(\".tiff\",\".ascii\"))\n",
    "    os.remove(i.replace(\".tiff\",\".vrt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## zonal analysis using merged tiff and watersheds \n",
    "pfafid_list = watersheds.index.tolist()\n",
    "headers_list = [\"pfaf_id\",\"Rain_TotalArea_km\",\"perc_Area\",\"MeanRain\",\"MaxRain\",]\n",
    "with open(filename.replace(\".vrt\",\".csv\"),'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(headers_list)  \n",
    "with open(filename.replace(\".vrt\",\".csv\"), 'a') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for the_pfafid in pfafid_list:\n",
    "        test_json = json.loads(gpd.GeoSeries([watersheds.loc[the_pfafid,'geometry']]).to_json())\n",
    "        data_points = HWRF_extract_by_mask(test_json,filename.replace(\".vrt\",\".tiff\"))\n",
    "            # write summary to a csv file\n",
    "        if (not data_points.empty):\n",
    "            HWRF_TotalArea_km = data_points['area'].sum()                \n",
    "            HWRF_perc_Area = HWRF_TotalArea_km/watersheds.loc[the_pfafid]['area_km2']*100\n",
    "            HWRF_MeanRain = data_points['intensity'].mean()\n",
    "            HWRF_MaxRain = data_points['intensity'].max() \n",
    "            results_list = [the_pfafid,HWRF_TotalArea_km,HWRF_perc_Area,HWRF_MeanRain,HWRF_MaxRain]\n",
    "            writer.writerow(results_list)"
   ]
  },

 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
