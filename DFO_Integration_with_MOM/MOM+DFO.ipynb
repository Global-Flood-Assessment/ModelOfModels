{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "from datetime import date,timedelta,datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file):\n",
    "    df = pd.read_csv(file)\n",
    "    df = pd.DataFrame(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mofunc(row):\n",
    "    if row['Severity'] > 0.8 or row['Hazard_Score'] > 80:\n",
    "        return 'Warning'\n",
    "    elif 0.6 < row['Severity'] < 0.80 or 60 < row['Hazard_Score'] < 80:\n",
    "        return 'Watch'\n",
    "    elif 0.35 < row['Severity'] < 0.6 or 35 < row['Hazard_Score'] < 60:\n",
    "        return 'Advisory'\n",
    "    else:\n",
    "        return 'Information'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forcast_date = date.today()\n",
    "cur_year, cur_month,cur_day = map(str,[forcast_date.today().year,forcast_date.today().month,forcast_date.today().day])\n",
    "cur_month = cur_month.zfill(2)\n",
    "cur_day=cur_day.zfill(2)\n",
    "MOMOutput='Final_Attributes_'+cur_year+cur_month+str(float(cur_day)-1)+'18.csv'\n",
    "DFO=\"DFO_\"+cur_year+cur_month+str(float(cur_day)-1)+'.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightage = read_data('weightage_DFO.csv')\n",
    "Attributes=read_data('Attributes.csv')\n",
    "PDC_resilience = read_data('Copy of Resilience_Index.csv')\n",
    "add_field_DFO=['DFO_area_1day_score', 'DFO_percarea_1day_score', 'DFO_area_2day_score', 'DFO_percarea_2day_score','DFO_area_3day_score', 'DFO_percarea_3day_score','DFOTotal_Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read DFO Processing data and calculate score\n",
    "with open(DFO, 'r', encoding='UTF-8') as DFO_file:\n",
    "    DFO_reader = csv.reader(DFO_file)\n",
    "    csvfile = open('DFO_w_score.csv', 'w', newline='\\n', encoding='utf-8')\n",
    "    DFO_w_score = csv.writer(csvfile)\n",
    "    row_count = 1\n",
    "    # csv_writer = csv.writer(write_obj)\n",
    "    for row in DFO_reader:\n",
    "        if row_count == 1:\n",
    "            for x in add_field_DFO:\n",
    "                row.append(x)\n",
    "            row_count = row_count + 1\n",
    "        else:\n",
    "            if float(row[4]) / float(weightage.DFO_Area_wt) > float(weightage.DFO_Area_max_pt):\n",
    "                DFO_area_1day_score = str(float(weightage.DFO_Area_max_pt)*float(weightage.one_Day_Multiplier))\n",
    "            else:\n",
    "                DFO_area_1day_score = str(float(weightage.DFO_Area_Min_pt) * float(weightage.one_Day_Multiplier)* float(row[4]) / float(weightage.DFO_Area_wt))\n",
    "            if float(row[5]) / float(weightage.DFO_percArea_wt) > float(weightage.DFO_percArea_Maxpt):\n",
    "                DFO_perc_area_1day_score = str(float(weightage.DFO_percArea_Maxpt)*float(weightage.one_Day_Multiplier))\n",
    "            else:\n",
    "                DFO_perc_area_1day_score = str(float(weightage.DFO_percArea_Minpt)*float(weightage.one_Day_Multiplier)* float(row[5]) / float(weightage.DFO_percArea_wt))\n",
    "            if float(row[6]) / float(weightage.DFO_Area_wt) > float(weightage.DFO_Area_max_pt):\n",
    "                DFO_area_2day_score = str(float(weightage.DFO_Area_max_pt)*float(weightage.two_Day_Multiplier))\n",
    "            else:\n",
    "                DFO_area_2day_score = str(float(weightage.DFO_Area_Min_pt) * float(weightage.two_Day_Multiplier)* float(row[6]) / float(weightage.DFO_Area_wt))\n",
    "            if float(row[7]) / float(weightage.DFO_percArea_wt) > float(weightage.DFO_percArea_Maxpt):\n",
    "                DFO_perc_area_2day_score = str(float(weightage.DFO_percArea_Maxpt)*float(weightage.two_Day_Multiplier))\n",
    "            else:\n",
    "                DFO_perc_area_2day_score = str(float(weightage.DFO_percArea_Minpt)*float(weightage.two_Day_Multiplier)* float(row[7]) / float(weightage.DFO_percArea_wt))\n",
    "            if float(row[8]) / float(weightage.DFO_Area_wt) > float(weightage.DFO_Area_max_pt):\n",
    "                DFO_area_3day_score = str(float(weightage.DFO_Area_max_pt)*float(weightage.three_Day_Multiplier))\n",
    "            else:\n",
    "                DFO_area_3day_score = str(float(weightage.DFO_Area_Min_pt) * float(weightage.three_Day_Multiplier)* float(row[8]) / float(weightage.DFO_Area_wt))\n",
    "            if float(row[9]) / float(weightage.DFO_percArea_wt) > float(weightage.DFO_percArea_Maxpt):\n",
    "                DFO_perc_area_3day_score = str(float(weightage.DFO_percArea_Maxpt)*float(weightage.three_Day_Multiplier))\n",
    "            else:\n",
    "                DFO_perc_area_3day_score = str(float(weightage.DFO_percArea_Minpt)*float(weightage.three_Day_Multiplier)* float(row[9]) / float(weightage.DFO_percArea_wt))\n",
    "                                          \n",
    "            Sum_Score = str(\n",
    "                (float(DFO_area_1day_score) + float(DFO_perc_area_1day_score) + float(DFO_area_2day_score) + float(DFO_perc_area_2day_score)+float(DFO_area_3day_score) + float(DFO_perc_area_3day_score)))\n",
    "            score_field = [DFO_area_1day_score, DFO_perc_area_1day_score, DFO_area_2day_score, DFO_perc_area_2day_score, DFO_area_3day_score, DFO_perc_area_3day_score,Sum_Score]\n",
    "            for x in score_field:\n",
    "                row.append(x)\n",
    "        DFO_w_score.writerow(row)\n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFO = read_data('DFO_w_score.csv')\n",
    "DFO = DFO[DFO.DFOTotal_Score > 0.1]\n",
    "DFO = DFO.iloc[:,1:]\n",
    "MOM = read_data(MOMOutput)\n",
    "MOM.drop(columns=['area_km2','ISO','Admin0','Admin1','rfr_score','cfr_score','Resilience_Index',' NormalizedLackofResilience ','Severity','Alert'], inplace=True)\n",
    "Final_Output_0= pd.merge(MOM.set_index('pfaf_id'), DFO.set_index('pfaf_id'), on='pfaf_id', how='outer')\n",
    "join1 = pd.merge(Attributes, PDC_resilience[['ISO', 'Resilience_Index', ' NormalizedLackofResilience ']], on='ISO', how='inner')\n",
    "Final_Output=pd.merge(join1.set_index('pfaf_id'), Final_Output_0, on='pfaf_id', how='outer')\n",
    "Final_Output[['Hazard_Score']] = Final_Output[['Hazard_Score']].fillna(value=0)\n",
    "Final_Output.loc[(Final_Output['Hazard_Score']!=0) & (Final_Output['Hazard_Score']<Final_Output['DFOTotal_Score']),'Flag']=2\n",
    "Final_Output['Hazard_Score'] =Final_Output[['Hazard_Score', 'DFOTotal_Score']].max(axis=1)\n",
    "Final_Output = Final_Output[Final_Output.Hazard_Score != 0]\n",
    "Final_Output = Final_Output.assign(\n",
    "    Scaled_Riverine_Risk=lambda x: Final_Output['rfr_score'] * 20)\n",
    "Final_Output = Final_Output.assign(\n",
    "    Scaled_Coastal_Risk=lambda x: Final_Output['cfr_score'] * 20)\n",
    "Final_Output = Final_Output.assign(\n",
    "    Severity=lambda x: scipy.stats.norm(np.log(100 - Final_Output[['Scaled_Riverine_Risk', 'Scaled_Coastal_Risk']].max(axis=1)), 1).cdf(\n",
    "        np.log(Final_Output['Hazard_Score'])))\n",
    "Final_Output['Alert'] = Final_Output.apply(mofunc, axis=1)\n",
    "Final_Output.to_csv('Final_Attributes_'+cur_year+cur_month+str(float(cur_day)-1)+'18_DFOUpdated.csv', encoding='utf-8-sig')\n",
    "join1 = pd.merge(Attributes, PDC_resilience[['ISO', 'Resilience_Index', ' NormalizedLackofResilience ']], on='ISO', how='inner')\n",
    "Attributes_Clean_DFO_Updated = pd.merge(join1.set_index('pfaf_id'), Final_Output[['Alert','Flag']], on='pfaf_id', how='right')\n",
    "Attributes_Clean_DFO_Updated.to_csv('Attributes_Clean'+cur_year+cur_month+str(float(cur_day)-1)+'18_DFOUpdated.csv', encoding='utf-8-sig')\n",
    "os.remove('DFO_w_score.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
